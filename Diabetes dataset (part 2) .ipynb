{"cells":[{"source":"#Load dataset\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_diabetes\nimport pandas as pd\nimport numpy as np\n\ndiabetes = load_diabetes()\ndf = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\nX = df.copy()\ny = pd.DataFrame(diabetes.target.copy(), columns=['target'])","metadata":{"executionCancelledAt":null,"executionTime":3232,"lastExecutedAt":1741789304324,"lastExecutedByKernel":"2cf0e012-54c6-45d8-8d75-96aecc8b965c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Load dataset\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_diabetes\nimport pandas as pd\nimport numpy as np\n\ndiabetes = load_diabetes()\ndf = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\nX = df.copy()\ny = pd.DataFrame(diabetes.target.copy(), columns=['target'])","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"id":"1cea761f-f1f0-4e11-a02a-83d2e3f76d48","cell_type":"code","execution_count":1,"outputs":[]},{"source":"#Prepare train and test sets for feature selection\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=123)\nprint(f'Train sets shapes: {X_train.shape}, {y_train.shape}')","metadata":{"executionCancelledAt":null,"executionTime":39,"lastExecutedAt":1741789311780,"lastExecutedByKernel":"2cf0e012-54c6-45d8-8d75-96aecc8b965c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Prepare train and test sets for feature selection\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=123)\nprint(f'Train sets shapes: {X_train.shape}, {y_train.shape}')","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"id":"25b2656d-cff6-4434-a586-8c147d3bfa5b","cell_type":"code","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"Train sets shapes: (375, 10), (375, 1)\n"}]},{"source":"#Import necessary components\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestClassifier\n","metadata":{"executionCancelledAt":null,"executionTime":156,"lastExecutedAt":1741789314191,"lastExecutedByKernel":"2cf0e012-54c6-45d8-8d75-96aecc8b965c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Import necessary components\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestClassifier\n"},"id":"64929c14-c90b-4b14-a0c0-a20a938a62d0","cell_type":"code","execution_count":3,"outputs":[]},{"source":"models = {}\n\n#Fit models\nlr = LinearRegression()\nmodels.update({'LinearRegression': lr})\n\nrf = RandomForestRegressor(random_state=123)\nmodels.update({'RandomForestRegressor': rf})\n\ngb = GradientBoostingRegressor(random_state=123)\nmodels.update({'GradientBoostingRegressor': gb})\n\n\n#Fit models and tune hyperparameters\nparams_rfr = {'n_estimators': [10, 50],  'max_depth': [2, 4], 'max_features': [5, 80], 'min_samples_leaf': [3, 6], 'random_state': [123]}\n\nparams_gbr = {'n_estimators': [10, 50], 'max_depth': [2, 4], 'max_features': [5, 10], 'min_samples_leaf': [5, 10], 'random_state': [123]}\n\nrfr = RandomForestRegressor(random_state=123)\ngbr = GradientBoostingRegressor(random_state=123)\n\n\ngrid_rfr= GridSearchCV(estimator = rfr, param_grid = params_rfr, scoring='neg_mean_absolute_error', n_jobs=4, cv= 5, refit=True, return_train_score=True)\ngrid_rfr.fit(X_train, y_train)\nmodels.update({'RandomForestRegressor_tuned': grid_rfr.best_estimator_})\nprint(grid_rfr.best_estimator_)\n\ngrid_gbr = GridSearchCV(estimator = gbr, param_grid = params_gbr, scoring='neg_mean_absolute_error', n_jobs=4, cv= 5, refit=True, return_train_score=True)\ngrid_gbr.fit(X_train, y_train)\nmodels.update({'GradientBoostingRegressor_tuned': grid_gbr.best_estimator_})\nprint(grid_gbr.best_estimator_)","cell_type":"code","id":"aea9906b-427c-463b-aa0e-b4862e6e68ae","outputs":[{"output_type":"stream","name":"stdout","text":"RandomForestRegressor(max_depth=4, max_features=5, min_samples_leaf=6,\n                      n_estimators=10, random_state=123)\nGradientBoostingRegressor(max_depth=2, max_features=5, min_samples_leaf=10,\n                          n_estimators=50, random_state=123)\n"}],"execution_count":4,"metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":101,"type":"stream"}}}},{"source":"#Baseline score\ncv = cross_validate(LinearRegression(), X_train, y_train, cv=5, scoring='r2', return_train_score=True)\nprint('test_score: ', cv['test_score'].mean(), ' train_score: ', cv['train_score'].mean())\n\n#Fit model with datasets and calculate scores\n\ndataset_scores = pd.DataFrame(columns=['model', 'test_score', 'train_score'])\n\nfor model_name, model in models.items():\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n          \n    train_score = model.score(X_train, y_train)\n    test_score = model.score(X_test, y_test)\n \n    row = [model_name, test_score, train_score]\n    dataset_scores.loc[len(dataset_scores)+1] = row\n    dataset_scores = dataset_scores.reset_index(drop=True)\n   \ndataset_scores.sort_values('test_score', ascending=False)","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":38,"type":"stream"},"1":{"height":50,"type":"dataFrame","tableState":{"quickFilterText":"","customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"f8ce9c31-2625-4ddb-8687-a7b89cd36ce7","nodeType":"const"}}}}},"id":"f3070798-1cb1-4951-b99b-4b8a4b2f7a58","cell_type":"code","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":"test_score:  0.4629812448078895  train_score:  0.503872956635694\n"},{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"model","type":"string"},{"name":"test_score","type":"number"},{"name":"train_score","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[4,0,3,2,1],"model":["GradientBoostingRegressor_tuned","LinearRegression","RandomForestRegressor_tuned","GradientBoostingRegressor","RandomForestRegressor"],"test_score":[0.5921574119,0.5910497012,0.5837139738,0.5689983769,0.5484148108],"train_score":[0.5959301935,0.5010076096,0.5792190893,0.8077294871,0.9157377991]}},"total_rows":5,"truncation_type":null},"text/plain":"                             model  test_score  train_score\n4  GradientBoostingRegressor_tuned    0.592157     0.595930\n0                 LinearRegression    0.591050     0.501008\n3      RandomForestRegressor_tuned    0.583714     0.579219\n2        GradientBoostingRegressor    0.568998     0.807729\n1            RandomForestRegressor    0.548415     0.915738","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>test_score</th>\n      <th>train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>GradientBoostingRegressor_tuned</td>\n      <td>0.592157</td>\n      <td>0.595930</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>LinearRegression</td>\n      <td>0.591050</td>\n      <td>0.501008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RandomForestRegressor_tuned</td>\n      <td>0.583714</td>\n      <td>0.579219</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GradientBoostingRegressor</td>\n      <td>0.568998</td>\n      <td>0.807729</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RandomForestRegressor</td>\n      <td>0.548415</td>\n      <td>0.915738</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":5}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}